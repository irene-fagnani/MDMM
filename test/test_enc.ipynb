{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d5682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting consistency test ---\n",
      "Using device: cpu\n",
      "\n",
      "--- Model Forward Pass Simulation ---\n",
      "Content A shape: torch.Size([1, 256, 27, 27]), Content B shape: torch.Size([1, 256, 27, 27])\n",
      "\n",
      "Attempting forward pass through the generator...\n",
      "\n",
      "--- Performing consistency checks ---\n",
      "Output shapes are correct.\n",
      "Outputs do not contain NaN or Inf values.\n",
      "Split operation is consistent.\n",
      "\n",
      " The entire pipeline consistency test passed successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the parent directory of 'src' to the Python path\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(current_dir, '../src')))\n",
    "\n",
    "import GMVAE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networks\n",
    "def get_z_random( batchSize, nz,num_classes,gpu, random_type='gauss'):\n",
    "    \"\"\"\n",
    "    Sample latent vectors from a mixture of Gaussian distributions.\n",
    "    :param batchSize: Number of samples.\n",
    "    :param nz: Dimensionality of the latent space.\n",
    "    :param random_type: Type of randomness ('gauss' or 'uniform').\n",
    "    :return: A batch of latent vectors sampled from the mixture.\n",
    "    \"\"\"\n",
    "    num_components=num_classes # number of gaussian components in the mixture equal to the number of classes\n",
    "    device = torch.device(f\"cuda:{gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if random_type == 'gauss':\n",
    "        # Mixture of Gaussians\n",
    "        # Define mixture weights (uniform for simplicity)\n",
    "        weights = torch.ones(num_components)/num_components\n",
    "        categorical = torch.distributions.Categorical(weights)\n",
    "\n",
    "        # Sample component indices for the batch\n",
    "        component_indices = categorical.sample((batchSize,)).to(device)\n",
    "\n",
    "        # Define means and standard deviations for each component\n",
    "        means = torch.randn(num_components, nz).to(device) * 2  # Centered around random points\n",
    "        stds = torch.ones(num_components, nz).to(device)  # Standard deviations of each Gaussian\n",
    "\n",
    "        # Create the latent vectors batch\n",
    "        z = torch.zeros(batchSize, nz).to(device)\n",
    "        for i in range(num_components):\n",
    "            mask = (component_indices == i).unsqueeze(1)  # Mask for samples from this component\n",
    "            z += mask * torch.normal(means[i], stds[i]).to(device)  # Sample from Gaussian i\n",
    "\n",
    "        return z\n",
    "\n",
    "# --- Test Script ---\n",
    "print(\"--- Starting consistency test ---\")\n",
    "\n",
    "# Example Parameters\n",
    "batch_size = 2\n",
    "input_dim = 3\n",
    "z_dim = 108\n",
    "y_dim = 3\n",
    "c_dim = 2\n",
    "img_size = 108\n",
    "gaussian_size = 108\n",
    "nz = 108\n",
    "num_classes = 2\n",
    "num_domains = 2\n",
    "x_dim = 256 # This needs to match the output channels of the content encoder\n",
    "crop_size = 108\n",
    "use_adain = False\n",
    "double_layer_ReLUINSConvTranspose = False\n",
    "half_size = batch_size // 2\n",
    "\n",
    "# Device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Instantiate your models\n",
    "content_encoder = networks.MD_E_content(input_dim=input_dim, use_cuda=torch.cuda.is_available()).to(device)\n",
    "attr_encoder = networks.MD_E_attr_concat(input_dim=input_dim, z_dim=gaussian_size, y_dim=num_classes, output_nc=nz, c_dim=num_domains, norm_layer=None, nl_layer=networks.get_non_linearity(layer_type='lrelu')).to(device)\n",
    "decoder = networks.MD_G_multi_concat(input_dim, x_dim, gaussian_size, crop_size, c_dim=num_domains, nz=nz, use_adain=use_adain, double_ConvT=double_layer_ReLUINSConvTranspose).to(device)\n",
    "\n",
    "# Dummy inputs\n",
    "x = torch.randn(batch_size, input_dim, img_size, img_size, device=device)\n",
    "c = F.one_hot(torch.randint(0, num_domains, (batch_size,)), num_classes=num_domains).float().to(device)\n",
    "\n",
    "print(\"\\n--- Model Forward Pass Simulation ---\")\n",
    "\n",
    "# Forward pass through content encoder\n",
    "content = content_encoder.forward(x)\n",
    "z_content_a, z_content_b = torch.split(content, half_size, dim=0)\n",
    "print(f\"Content A shape: {z_content_a.shape}, Content B shape: {z_content_b.shape}\")\n",
    "\n",
    "# Forward pass through attribute encoder\n",
    "inf = attr_encoder.forward(x, c, temperature=1.0, hard=False)\n",
    "z_attr = inf[\"gaussian\"]\n",
    "y = inf[\"categorical\"]\n",
    "z_attr_a, z_attr_b = torch.split(z_attr, half_size, dim=0)\n",
    "z_random = get_z_random(half_size, nz, num_classes, 0)\n",
    "\n",
    "# Construct inputs for the generator\n",
    "input_content_forA = torch.cat((z_content_b, z_content_a, z_content_b), 0)\n",
    "input_content_forB = torch.cat((z_content_a, z_content_b, z_content_a), 0)\n",
    "input_attr_forA = torch.cat((z_attr_a, z_attr_a, z_random), 0)\n",
    "input_attr_forB = torch.cat((z_attr_b, z_attr_b, z_random), 0)\n",
    "y_a = y[0:half_size]\n",
    "y_b = y[half_size:]\n",
    "input_y_forA = torch.cat((y_a, y_a, y_a), dim=0)\n",
    "input_y_forB = torch.cat((y_b, y_b, y_b), dim=0)\n",
    "\n",
    "# Forward pass through the decoder (generator)\n",
    "try:\n",
    "    print(\"\\nAttempting forward pass through the generator...\")\n",
    "    outA = decoder.forward(input_content_forA, input_attr_forA, input_y_forA, y_a)\n",
    "    outB = decoder.forward(input_content_forB, input_attr_forB, input_y_forB, y_b)\n",
    "\n",
    "    # --- Consistency Checks ---\n",
    "    print(\"\\n--- Performing consistency checks ---\")\n",
    "\n",
    "    # Extract reconstructed images\n",
    "    fake_A_encoded = outA['x_rec']\n",
    "    fake_B_encoded = outB['x_rec']\n",
    "\n",
    "    # 1. Check output dimensions\n",
    "    expected_shape = (half_size * 3, input_dim, img_size, img_size)\n",
    "    assert fake_A_encoded.shape == expected_shape, f\"Dimension mismatch for output A. Expected: {expected_shape}, Got: {fake_A_encoded.shape}\"\n",
    "    assert fake_B_encoded.shape == expected_shape, f\"Dimension mismatch for output B. Expected: {expected_shape}, Got: {fake_B_encoded.shape}\"\n",
    "    print(\"Output shapes are correct.\")\n",
    "\n",
    "    # 2. Check for finite values (no NaN or Inf)\n",
    "    assert torch.isfinite(fake_A_encoded).all(), \"Output A contains non-finite values (NaN or Inf).\"\n",
    "    assert torch.isfinite(fake_B_encoded).all(), \"Output B contains non-finite values (NaN or Inf).\"\n",
    "    print(\"Outputs do not contain NaN or Inf values.\")\n",
    "\n",
    "    # 3. Check split operation consistency \n",
    "    split_A = torch.split(fake_A_encoded, half_size, dim=0)\n",
    "    split_B = torch.split(fake_B_encoded, half_size, dim=0)\n",
    "    \n",
    "    expected_split_shape = (half_size, input_dim, img_size, img_size)\n",
    "    assert all(s.shape == expected_split_shape for s in split_A), \"Error in output A split.\"\n",
    "    assert all(s.shape == expected_split_shape for s in split_B), \"Error in output B split.\"\n",
    "    print(\"Split operation is consistent.\")\n",
    "\n",
    "    print(\"\\n The entire pipeline consistency test passed successfully!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n Test Failed: An unexpected error occurred. {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
