--- load options ---
batch_size: 2
concat: 1
crop_size: 216
d_iter: 3
dataroot: datasets/mini
dis_norm: None
dis_scale: 3
dis_spectral_norm: False
display_dir: DISPLAY
display_freq: 10
gaussian_size: 64
gpu: 0
img_save_freq: 5
input_dim: 3
isDcontent: True
lambda_cls: 1.0
lambda_cls_G: 5.0
lambda_rec: 10
lr_policy: lambda
model_save_freq: 10
nThreads: 8
n_ep: 1200
n_ep_decay: 600
name: outputs
no_display_img: False
no_flip: False
num_classes: 2
num_domains: 2
phase: train
resize_size: 256
result_dir: RESULT
resume: None
x_dim: 262144

--- load dataset ---

--- load model ---
x_dim 64 2 64
start the training at epoch 0

--- train ---
Entra in forward infNet
Entra in qyx
entra in else
layer: Linear(in_features=64, out_features=512, bias=True)
entra in else
layer: ReLU()
entra in else
layer: Linear(in_features=512, out_features=512, bias=True)
entra in else
layer: ReLU()
entra in if
Esce da qyx
Esce da forward infNet
Entra in forward infNet
Entra in qyx
entra in else
layer: Linear(in_features=64, out_features=512, bias=True)
entra in else
layer: ReLU()
entra in else
layer: Linear(in_features=512, out_features=512, bias=True)
entra in else
layer: ReLU()
entra in if
Esce da qyx
Esce da forward infNet
log tensor([[-0.3530, -0.3660, -0.4020, -0.3629, -0.3396, -0.3898, -0.3299, -0.4077,
         -0.3521, -0.3715, -0.3685, -0.3931, -0.3883, -0.4102, -0.3591, -0.4140,
         -0.3796, -0.3756, -0.3271, -0.3726, -0.3935, -0.3627, -0.3761, -0.3725,
         -0.3830, -0.3526, -0.3728, -0.3728, -0.3717, -0.3765, -0.3658, -0.3455,
         -0.3997, -0.3721, -0.3453, -0.3082, -0.3509, -0.3321, -0.4055, -0.3609,
         -0.4080, -0.3545, -0.3344, -0.3862, -0.3518, -0.3562, -0.3868, -0.3727,
         -0.3487, -0.3821, -0.4001, -0.3291, -0.3821, -0.3954, -0.3887, -0.3822,
         -0.3446, -0.3569, -0.4000, -0.3701, -0.3442, -0.3830, -0.3581, -0.3673],
        [-0.3446, -0.3597, -0.3975, -0.3639, -0.3448, -0.3939, -0.3293, -0.4040,
         -0.3547, -0.3709, -0.3643, -0.3887, -0.3834, -0.4047, -0.3556, -0.4194,
         -0.3757, -0.3716, -0.3220, -0.3591, -0.3946, -0.3616, -0.3707, -0.3751,
         -0.3820, -0.3524, -0.3737, -0.3768, -0.3700, -0.3754, -0.3574, -0.3511,
         -0.4027, -0.3698, -0.3502, -0.3149, -0.3575, -0.3319, -0.4112, -0.3586,
         -0.4027, -0.3622, -0.3324, -0.3866, -0.3509, -0.3452, -0.3888, -0.3750,
         -0.3440, -0.3763, -0.3928, -0.3338, -0.3737, -0.4065, -0.3886, -0.3811,
         -0.3472, -0.3587, -0.3995, -0.3656, -0.3446, -0.3887, -0.3599, -0.3690]],
       device='cuda:0', grad_fn=<LogBackward0>)
z_attra torch.Size([1, 64])
z_random torch.Size([1, 64])
y torch.Size([3, 64])
size xcz torch.Size([3, 386, 54, 54])
Traceback (most recent call last):
  File "/home/davide/Greta/DRIT/MDM/MDMM/train.py", line 88, in <module>
    main()
  File "/home/davide/Greta/DRIT/MDM/MDMM/train.py", line 59, in main
    model.update_D(images, c_org)
  File "/home/davide/Greta/DRIT/MDM/MDMM/model.py", line 213, in update_D
    self.forward()
  File "/home/davide/Greta/DRIT/MDM/MDMM/model.py", line 159, in forward
    output_fakeA = self.gen.forward(input_content_forA, input_attr_forA, input_c_forA)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/MDM/MDMM/networks.py", line 164, in forward
    out1 = self.dec1(x_c_z)
           ^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/MDM/MDMM/networks.py", line 420, in forward
    out = self.model(x)
          ^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py", line 250, in forward
    input = module(input)
            ^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 554, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/davide/Greta/DRIT/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py", line 549, in _conv_forward
    return F.conv2d(
           ^^^^^^^^^
RuntimeError: Given groups=1, weight of size [322, 322, 3, 3], expected input[3, 386, 56, 56] to have 322 channels, but got 386 channels instead