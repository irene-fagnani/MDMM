{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d5682f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Istanzia encoder e decoder\u001b[39;00m\n\u001b[1;32m     21\u001b[0m content_encoder \u001b[38;5;241m=\u001b[39m networks\u001b[38;5;241m.\u001b[39mMD_E_content(input_dim\u001b[38;5;241m=\u001b[39minput_dim, use_cuda\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m attr_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mnetworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMD_E_attr_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43moutput_nc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m decoder \u001b[38;5;241m=\u001b[39m networks\u001b[38;5;241m.\u001b[39mMD_G_multi_concat(output_dim\u001b[38;5;241m=\u001b[39minput_dim, x_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, z_dim\u001b[38;5;241m=\u001b[39mz_dim,\n\u001b[1;32m     25\u001b[0m crop_size\u001b[38;5;241m=\u001b[39mimg_size, c_dim\u001b[38;5;241m=\u001b[39mc_dim, nz\u001b[38;5;241m=\u001b[39mz_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Input fittizio (immagini da due domini + condizioni)\u001b[39;00m\n",
      "File \u001b[0;32m~/MDMM/src/test/networks.py:78\u001b[0m, in \u001b[0;36mMD_E_attr_concat.__init__\u001b[0;34m(self, input_dim, z_dim, y_dim, output_nc, c_dim, norm_layer, nl_layer)\u001b[0m\n\u001b[1;32m     76\u001b[0m   input_ndf \u001b[38;5;241m=\u001b[39m ndf \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_ndf, n)  \u001b[38;5;66;03m# 2**(n-1)\u001b[39;00m\n\u001b[1;32m     77\u001b[0m   output_ndf \u001b[38;5;241m=\u001b[39m ndf \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_ndf, n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 2**n\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m   conv_layers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mBasicBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ndf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ndf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnl_layer\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     79\u001b[0m conv_layers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [nl_layer(), nn\u001b[38;5;241m.\u001b[39mAdaptiveAvgPool2d(\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;66;03m# AvgPool2d(13)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39m[nn\u001b[38;5;241m.\u001b[39mLinear(output_ndf, output_nc)])\n",
      "File \u001b[0;32m~/MDMM/src/test/networks.py:447\u001b[0m, in \u001b[0;36mBasicBlock.__init__\u001b[0;34m(self, inplanes, outplanes, norm_layer, nl_layer)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m   layers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [norm_layer(inplanes)]\n\u001b[0;32m--> 447\u001b[0m layers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[43mnl_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    448\u001b[0m layers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m conv3x3(inplanes, inplanes)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m norm_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "import GMVAE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networks\n",
    "# Parametri di esempio\n",
    "batch_size = 2\n",
    "input_dim = 3 # immagine RGB\n",
    "z_dim = 8\n",
    "y_dim = 3\n",
    "c_dim = 3\n",
    "img_size = 64\n",
    "\n",
    "\n",
    "# Selezione device (usa GPU se disponibile)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# Istanzia encoder e decoder\n",
    "content_encoder = networks.MD_E_content(input_dim=input_dim, use_cuda=torch.cuda.is_available()).to(device)\n",
    "attr_encoder = networks.MD_E_attr_concat(input_dim=input_dim, z_dim=z_dim, y_dim=y_dim,\n",
    "output_nc=8, c_dim=c_dim,\n",
    "norm_layer=nn.BatchNorm2d, nl_layer=nn.ReLU).to(device)\n",
    "decoder = networks.MD_G_multi_concat(output_dim=input_dim, x_dim=8, z_dim=z_dim,\n",
    "crop_size=img_size, c_dim=c_dim, nz=z_dim,\n",
    "use_adain=False, double_ConvT=False).to(device)\n",
    "\n",
    "\n",
    "# Input fittizio (immagini da due domini + condizioni)\n",
    "x_a = torch.randn(batch_size, input_dim, img_size, img_size, device=device)\n",
    "x_b = torch.randn(batch_size, input_dim, img_size, img_size, device=device)\n",
    "c_a = torch.randn(batch_size, c_dim, device=device)\n",
    "c_b = torch.randn(batch_size, c_dim, device=device)\n",
    "z_random = torch.randn(batch_size, z_dim, device=device)\n",
    "\n",
    "\n",
    "# --- Forward content encoder ---\n",
    "content_a = content_encoder.forward(x_a)\n",
    "content_b = content_encoder.forward(x_b)\n",
    "print(\"Content A:\", content_a.shape, \"Content B:\", content_b.shape)\n",
    "\n",
    "\n",
    "# --- Forward attribute encoder ---\n",
    "attr_out_a = attr_encoder.forward(x_a, c_a, temperature=1.0, hard=0)\n",
    "attr_out_b = attr_encoder.forward(x_b, c_b, temperature=1.0, hard=0)\n",
    "\n",
    "\n",
    "attr_a = attr_out_a[\"gaussian\"]\n",
    "attr_b = attr_out_b[\"gaussian\"]\n",
    "y_a = attr_out_a[\"categorical\"]\n",
    "y_b = attr_out_b[\"categorical\"]\n",
    "\n",
    "\n",
    "# Costruzione input come in DRIT++\n",
    "input_content_forA = torch.cat((content_b, content_a, content_b), 0)\n",
    "input_content_forB = torch.cat((content_a, content_b, content_a), 0)\n",
    "\n",
    "\n",
    "input_attr_forA = torch.cat((attr_a, attr_a, z_random), 0)\n",
    "input_attr_forB = torch.cat((attr_b, attr_b, z_random), 0)\n",
    "\n",
    "\n",
    "input_y_forA = torch.cat((y_a, y_a, y_a), 0)\n",
    "input_y_forB = torch.cat((y_b, y_b, y_b), 0)\n",
    "\n",
    "\n",
    "input_c_forA = torch.cat((c_a, c_a, c_a), 0)\n",
    "input_c_forB = torch.cat((c_b, c_b, c_b), 0)\n",
    "\n",
    "\n",
    "# --- Forward generator (decoder) ---\n",
    "outA = decoder.forward(input_content_forA, input_attr_forA, input_c_forA, y_a)\n",
    "outB = decoder.forward(input_content_forB, input_attr_forB, input_c_forB, y_b)\n",
    "\n",
    "\n",
    "print(\"Decoder outA keys:\", outA.keys())\n",
    "print(\"Decoder outB keys:\", outB.keys())\n",
    "\n",
    "\n",
    "# Controlli\n",
    "assert \"x_img\" in outA and \"x_img\" in outB, \"Decoder deve produrre immagine ricostruita (x_img)\"\n",
    "assert \"x_rec\" in outA and \"x_rec\" in outB, \"Decoder deve produrre ricostruzione vettoriale (x_rec)\"\n",
    "\n",
    "\n",
    "assert outA[\"x_img\"].ndim == 4 and outB[\"x_img\"].ndim == 4, \"x_img deve essere (B,C,H,W)\"\n",
    "assert outA[\"x_rec\"].ndim == 2 and outB[\"x_rec\"].ndim == 2, \"x_rec deve essere (B,features)\"\n",
    "\n",
    "\n",
    "print(\"\\nTutti i test di consistenza passati âœ…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
